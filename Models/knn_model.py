# -*- coding: utf-8 -*-
"""knn_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z1dR7CNKaT0NgI0pojqLrFjXVIKDxOt2
"""

from __future__ import annotations
import argparse
from pathlib import Path
import warnings
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from collections import Counter
import sys

# A. PREPROCESSING FUNCTIONS

def load_raw(path: Path) -> pd.DataFrame:
    df = pd.read_csv("/content/cardio_train.csv", sep=";")
    df.columns = [c.strip().lower() for c in df.columns]
    return df

def basic_sanity_fixes(df: pd.DataFrame) -> pd.DataFrame:
    if "age" in df.columns:
        df["age"] = (df["age"] / 365.25).astype(int)

    if {"ap_hi", "ap_lo"}.issubset(df.columns):
        swapped = df["ap_hi"] < df["ap_lo"]
        df.loc[swapped, ["ap_hi", "ap_lo"]] = df.loc[swapped, ["ap_lo", "ap_hi"]].values

    rules = [
        ("age", 30, 80),
        ("height", 130, 210),
        ("weight", 40, 200),
        ("ap_hi", 80, 240),
        ("ap_lo", 40, 150),
    ]
    for col, lo, hi in rules:
        if col in df.columns:
            df = df[(df[col] >= lo) & (df[col] <= hi)]

    df = df.drop_duplicates(ignore_index=True)
    return df

def add_features(df: pd.DataFrame) -> pd.DataFrame:
    if {"height", "weight"}.issubset(df.columns):
        h_m = df["height"] / 100.0
        df["bmi"] = (df["weight"] / (h_m ** 2)).round(3)

    if {"ap_hi", "ap_lo"}.issubset(df.columns):
        df["pulse_pressure"] = (df["ap_hi"] - df["ap_lo"]).astype(int)

    if "age" in df.columns:
        df["age_group"] = pd.cut(
            df["age"],
            bins=[29, 39, 49, 59, 69, 120],
            labels=["30s", "40s", "50s", "60s", "70+"],
        )

    for c in ["gender", "cholesterol", "gluc", "smoke", "alco", "active"]:
        if c in df.columns:
            df[c] = df[c].astype("category")

    return df

def impute_and_scale(df: pd.DataFrame, columns_to_scale: list[str]) -> tuple[pd.DataFrame, StandardScaler]:
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    for c in num_cols:
        if df[c].isna().any():
            df[c] = df[c].fillna(df[c].median())

    scaler = StandardScaler()
    cols = [c for c in columns_to_scale if c in df.columns]
    if cols:
        df[cols] = scaler.fit_transform(df[cols])
    return df, scaler

def get_processed_data(input_csv: Path) -> tuple[np.ndarray, np.ndarray]:
    """Runs the full preprocessing pipeline and prepares X and y arrays for modeling."""
    df = load_raw(input_csv)
    df = basic_sanity_fixes(df)
    df = add_features(df)

    cols_to_scale = ["age", "height", "weight", "ap_hi", "ap_lo", "bmi", "pulse_pressure"]
    df_scaled, _ = impute_and_scale(df, cols_to_scale)

    # Convert categorical/object columns to numerical using one-hot encoding for modeling
    df_model = pd.get_dummies(df_scaled.drop(['id', 'age_group'], axis=1), drop_first=True)

    # Separate features and target
    X = df_model.drop('cardio', axis=1).values
    y = df_model['cardio'].values

    return X, y

# B. CUSTOM K-NN CLASSIFIER

class CustomKNN:
    def __init__(self, k: int = 5):
        """Initializes the k-NN classifier. k is the number of neighbors."""
        self.k = k

    def fit(self, X: np.ndarray, y: np.ndarray):
        """Stores the training data (Lazy Learner)."""
        self.X_train = X
        self.y_train = y

    def _euclidean_distance(self, x1: np.ndarray, x2: np.ndarray) -> float:
        """Calculates the Euclidean distance between two vectors."""
        # Distance formula: sqrt( sum( (x1_i - x2_i)^2 ) )
        return np.linalg.norm(x1 - x2)

    def _predict(self, x_new: np.ndarray) -> int:
        """Predicts the class label for a single new data point."""
        # 1. Calculate distances to all training points
        distances = [self._euclidean_distance(x_new, x_train) for x_train in self.X_train]

        # 2. Get the indices of the k smallest distances
        k_indices = np.argsort(distances)[:self.k]

        # 3. Extract the class labels for those k neighbors
        k_nearest_labels = [self.y_train[i] for i in k_indices]

        # 4. Majority vote: get the most frequent class label
        most_common = Counter(k_nearest_labels).most_common(1)

        return most_common[0][0]

    def predict(self, X: np.ndarray) -> np.ndarray:
        """Predicts the class labels for an array of test data points."""
        predictions = np.array([self._predict(x) for x in X])
        return predictions

# C. EXECUTION, EVALUATION, AND REPORTING

def run_knn_experiment():
    # 1. Load and prepare data (using your existing robust pipeline)
    X, y = get_processed_data(Path("/content/cardio_train.csv"))

    # Split the data into training and testing sets (80/20 split)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # 2. Define K values to test (You must test several to find the best K)
    K_VALUES = [5, 7, 9, 11]

    results = {}

    print("\n--- Running Custom k-NN Model Training and Evaluation ---")

    for k in K_VALUES:
        # 3. Initialize and Train the custom k-NN model
        custom_knn = CustomKNN(k=k)
        custom_knn.fit(X_train, y_train)

        # 4. Make predictions
        y_pred = custom_knn.predict(X_test)

        # 5. Calculate ALL required metrics for the Progress Report (Section 4.g)
        # Note: k-NN from scratch only outputs hard predictions (0 or 1),
        # so ROC-AUC is calculated using the predicted classes as proxy scores.
        metrics = {
            'Accuracy': accuracy_score(y_test, y_pred),
            'Precision': precision_score(y_test, y_pred),
            'Recall': recall_score(y_test, y_pred),
            'F1-Score': f1_score(y_test, y_pred),
            'ROC-AUC': roc_auc_score(y_test, y_pred)  # Using predicted classes as proxy scores
        }

        results[k] = metrics

        print(f"\nResults for K = {k}:")
        for metric, value in metrics.items():
            print(f"  {metric}: {value:.4f}")

    # Final summary for report analysis
    print("\n--- Summary for Progress Report ---")
    best_k = max(results, key=lambda k: results[k]['F1-Score'])
    print(f"Best K value (based on F1-Score): {best_k}")
    print(f"Metrics for Best K ({best_k}): {results[best_k]}")

if __name__ == '__main__':
    # Check if running in an interactive environment and clear args for smooth execution
    if 'ipykernel' in sys.modules or 'google.colab' in sys.modules:
        if len(sys.argv) > 1:
            sys.argv = [sys.argv[0]]

    # Execute the experiment
    run_knn_experiment()